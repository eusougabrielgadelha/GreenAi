# üöÄ Melhorias Priorit√°rias no C√≥digo

## üìä An√°lise Completa

Baseado na an√°lise do c√≥digo, aqui est√£o as principais melhorias organizadas por prioridade e categoria.

---

## üî¥ PRIORIDADE ALTA (Cr√≠tico para Funcionamento)

### 1. **Melhorar Extra√ß√£o de Resultado do Jogo**

**Problema Atual:**
- A fun√ß√£o `scrape_game_result()` depende apenas de encontrar texto "Vencedor" no HTML
- Muito fr√°gil - pode falhar se a estrutura HTML mudar
- Retorna `None` frequentemente, exigindo m√∫ltiplas tentativas

**Melhorias Sugeridas:**

#### A. Extrair do Placar Final
```python
def scrape_game_result(html: str, ext_id: str) -> Optional[str]:
    soup = BeautifulSoup(html, "html.parser")
    
    # NOVA ESTRAT√âGIA: Extrair do placar final
    # Exemplo: "2 - 1" significa casa venceu
    score_elements = soup.select('.score, .result, [class*="score"]')
    for elem in score_elements:
        score_text = elem.get_text(strip=True)
        # Parsear "2 - 1" ou "2:1" ou "2 x 1"
        match = re.search(r'(\d+)\s*[-:x]\s*(\d+)', score_text)
        if match:
            home_goals = int(match.group(1))
            away_goals = int(match.group(2))
            if home_goals > away_goals:
                return "home"
            elif away_goals > home_goals:
                return "away"
            else:
                return "draw"
    
    # Estrat√©gias existentes (manter como fallback)
    # ...
```

#### B. Usar API XHR para Resultado
```python
async def fetch_game_result(ext_id: str, source_link: str) -> Optional[str]:
    # Tentar API primeiro
    event_id = extract_event_id_from_url(source_link) or int(ext_id)
    json_data = await fetch_event_odds_from_api_async(event_id)
    
    if json_data:
        # Verificar se h√° resultado na API
        event = json_data.get('events', [{}])[0]
        # Verificar event_status_id ou score
        if event.get('event_status_id') == 2:  # Terminado
            # Extrair placar ou resultado
            # ...
    
    # Fallback para HTML scraping melhorado
    # ...
```

**Impacto:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Cr√≠tico - afeta verifica√ß√£o de resultados)

---

### 2. **Cache de Resultados**

**Problema:**
- Sistema busca resultado m√∫ltiplas vezes para o mesmo jogo
- M√∫ltiplas requisi√ß√µes desnecess√°rias

**Solu√ß√£o:**
```python
# Adicionar cache em mem√≥ria ou banco
from functools import lru_cache
from datetime import datetime, timedelta

@lru_cache(maxsize=1000)
def get_cached_result(event_id: str, ttl_minutes: int = 60) -> Optional[str]:
    # Verificar se resultado j√° foi buscado recentemente
    # Retornar do cache se v√°lido
    pass
```

**Impacto:** ‚≠ê‚≠ê‚≠ê‚≠ê (Alto - melhora performance)

---

### 3. **Rate Limiting e Retry com Backoff**

**Problema:**
- M√∫ltiplas requisi√ß√µes simult√¢neas podem causar 403
- Sem controle de rate limiting

**Solu√ß√£o:**
```python
import asyncio
from time import time

class RateLimiter:
    def __init__(self, max_requests: int = 10, window: int = 60):
        self.max_requests = max_requests
        self.window = window
        self.requests = []
    
    async def acquire(self):
        now = time()
        # Remove requisi√ß√µes antigas
        self.requests = [r for r in self.requests if now - r < self.window]
        
        if len(self.requests) >= self.max_requests:
            sleep_time = self.window - (now - self.requests[0])
            await asyncio.sleep(sleep_time)
        
        self.requests.append(now)

# Usar com backoff exponencial
async def fetch_with_retry(url: str, max_retries: int = 3):
    for attempt in range(max_retries):
        try:
            await rate_limiter.acquire()
            return await fetch(url)
        except Exception as e:
            if attempt < max_retries - 1:
                await asyncio.sleep(2 ** attempt)  # Backoff exponencial
            else:
                raise
```

**Impacto:** ‚≠ê‚≠ê‚≠ê‚≠ê (Alto - reduz 403 errors)

---

## üü° PRIORIDADE M√âDIA (Melhorias Importantes)

### 4. **Melhorar Tratamento de Erros**

**Problema:**
- Alguns erros s√£o silenciosamente ignorados
- Falta contexto em alguns logs

**Solu√ß√£o:**
```python
# Adicionar contexto detalhado em todos os erros
try:
    result = await fetch_data()
except Exception as e:
    logger.error(
        "Erro ao buscar dados",
        extra={
            "error_type": type(e).__name__,
            "error_message": str(e),
            "url": url,
            "ext_id": ext_id,
            "traceback": traceback.format_exc()
        }
    )
    raise
```

**Impacto:** ‚≠ê‚≠ê‚≠ê (M√©dio - facilita debug)

---

### 5. **Valida√ß√£o de Dados**

**Problema:**
- Dados da API n√£o s√£o validados antes de usar
- Pode causar erros inesperados

**Solu√ß√£o:**
```python
from typing import Optional
from pydantic import BaseModel, validator

class EventData(BaseModel):
    event_id: int
    home: str
    away: str
    odds_home: float
    odds_draw: float
    odds_away: float
    
    @validator('odds_home', 'odds_draw', 'odds_away')
    def validate_odds(cls, v):
        if v < 1.0 or v > 100:
            raise ValueError(f"Odd inv√°lida: {v}")
        return v

# Usar para validar dados antes de processar
def parse_events_from_api(json_data: Dict[str, Any], source_url: str) -> List[Any]:
    events = []
    for item in json_data.get('odds', []):
        try:
            event_data = EventData(**item)
            events.append(event_data)
        except ValidationError as e:
            logger.warning(f"Dados inv√°lidos ignorados: {e}")
    return events
```

**Impacto:** ‚≠ê‚≠ê‚≠ê (M√©dio - previne erros)

---

### 6. **Otimiza√ß√£o de Queries do Banco**

**Problema:**
- Poss√≠veis N+1 queries em alguns lugares
- Falta de √≠ndices em alguns campos

**Solu√ß√£o:**
```python
# Usar eager loading
from sqlalchemy.orm import joinedload

games = session.query(Game)\
    .options(joinedload(Game.tracker))\
    .filter(Game.status == "live")\
    .all()

# Adicionar √≠ndices
# models/database.py
class Game(Base):
    __table_args__ = (
        Index('idx_game_status', 'status'),
        Index('idx_game_start_time', 'start_time'),
        Index('idx_game_ext_id', 'ext_id'),
    )
```

**Impacto:** ‚≠ê‚≠ê‚≠ê (M√©dio - melhora performance)

---

### 7. **Monitoramento e Alertas**

**Problema:**
- Falta de m√©tricas de sa√∫de do sistema
- N√£o h√° alertas para problemas cr√≠ticos

**Solu√ß√£o:**
```python
# Adicionar health checks
class SystemHealth:
    def check_api_health(self) -> bool:
        # Verificar se API est√° respondendo
        pass
    
    def check_db_health(self) -> bool:
        # Verificar conex√£o com banco
        pass
    
    def check_telegram_health(self) -> bool:
        # Verificar se Telegram est√° funcionando
        pass

# Alertar quando problemas cr√≠ticos
if not health.check_api_health():
    tg_send_message("‚ö†Ô∏è API n√£o est√° respondendo!", alert_type="critical")
```

**Impacto:** ‚≠ê‚≠ê‚≠ê (M√©dio - melhora observabilidade)

---

## üü¢ PRIORIDADE BAIXA (Otimiza√ß√µes e Refatora√ß√µes)

### 8. **Cache de Campeonatos**

**Problema:**
- Lista de campeonatos √© buscada toda vez
- Poderia ser cacheada

**Solu√ß√£o:**
```python
from functools import lru_cache
from datetime import datetime, timedelta

@lru_cache(maxsize=1)
def get_cached_tournaments(cache_time: str = None):
    # Cache v√°lido por 24 horas
    return get_all_football_tournaments()

# Invalidar cache quando necess√°rio
get_cached_tournaments.cache_clear()
```

**Impacto:** ‚≠ê‚≠ê (Baixo - melhora performance)

---

### 9. **Refatorar Fun√ß√µes Longas**

**Problema:**
- Algumas fun√ß√µes s√£o muito longas (ex: `monitor_live_games_job`)
- Dif√≠cil de manter e testar

**Solu√ß√£o:**
```python
# Dividir em fun√ß√µes menores
async def monitor_live_games_job():
    games = get_live_games()
    for game in games:
        await process_live_game(game)

async def process_live_game(game):
    if game.status == "ended":
        await handle_finished_game(game)
    else:
        await handle_active_game(game)

async def handle_finished_game(game):
    # Buscar resultado
    # Comparar com palpite
    # Enviar notifica√ß√£o
    pass

async def handle_active_game(game):
    # Monitorar jogo ao vivo
    # Buscar oportunidades
    pass
```

**Impacto:** ‚≠ê‚≠ê (Baixo - melhora manutenibilidade)

---

### 10. **Adicionar Testes Unit√°rios**

**Problema:**
- Falta de testes automatizados
- Mudan√ßas podem quebrar funcionalidades

**Solu√ß√£o:**
```python
# tests/test_scraping.py
import pytest
from scraping.betnacional import extract_ids_from_url

def test_extract_ids_from_url():
    assert extract_ids_from_url("https://betnacional.bet.br/events/1/0/7") == (1, 0, 7)
    assert extract_ids_from_url("invalid") is None

# tests/test_decision.py
def test_decide_bet():
    # Testar l√≥gica de decis√£o
    pass
```

**Impacto:** ‚≠ê‚≠ê (Baixo - melhora confiabilidade)

---

### 11. **Configura√ß√£o Centralizada de Timeouts**

**Problema:**
- Timeouts hardcoded em v√°rios lugares
- Dif√≠cil ajustar globalmente

**Solu√ß√£o:**
```python
# config/settings.py
API_TIMEOUT = float(os.getenv("API_TIMEOUT", "20"))
HTML_TIMEOUT = float(os.getenv("HTML_TIMEOUT", "30"))
RESULT_CHECK_TIMEOUT = float(os.getenv("RESULT_CHECK_TIMEOUT", "10"))

# Usar em todos os lugares
response = requests.get(url, timeout=API_TIMEOUT)
```

**Impacto:** ‚≠ê‚≠ê (Baixo - melhora configurabilidade)

---

### 12. **Melhorar Logging Estruturado**

**Problema:**
- Logs n√£o estruturados dificultam an√°lise
- Falta de contexto em alguns logs

**Solu√ß√£o:**
```python
import structlog

logger = structlog.get_logger()

# Logs estruturados
logger.info(
    "evento_processado",
    game_id=game.id,
    ext_id=game.ext_id,
    status=game.status,
    duration_ms=elapsed_time
)
```

**Impacto:** ‚≠ê‚≠ê (Baixo - melhora observabilidade)

---

## üìã Resumo por Prioridade

### üî¥ Alta Prioridade (Fazer Agora)
1. ‚úÖ Melhorar extra√ß√£o de resultado do jogo
2. ‚úÖ Cache de resultados
3. ‚úÖ Rate limiting e retry com backoff

### üü° M√©dia Prioridade (Fazer em Breve)
4. ‚úÖ Melhorar tratamento de erros
5. ‚úÖ Valida√ß√£o de dados
6. ‚úÖ Otimiza√ß√£o de queries
7. ‚úÖ Monitoramento e alertas

### üü¢ Baixa Prioridade (Otimiza√ß√µes Futuras)
8. ‚úÖ Cache de campeonatos
9. ‚úÖ Refatorar fun√ß√µes longas
10. ‚úÖ Adicionar testes unit√°rios
11. ‚úÖ Configura√ß√£o centralizada
12. ‚úÖ Logging estruturado

---

## üéØ Recomenda√ß√£o de Implementa√ß√£o

**Ordem Sugerida:**

1. **Semana 1:** Melhorar extra√ß√£o de resultado (#1)
2. **Semana 2:** Cache de resultados (#2) + Rate limiting (#3)
3. **Semana 3:** Valida√ß√£o de dados (#5) + Tratamento de erros (#4)
4. **Semana 4:** Otimiza√ß√£o de queries (#6) + Monitoramento (#7)
5. **Futuro:** Itens de baixa prioridade conforme necess√°rio

---

## üí° Melhorias Espec√≠ficas por √Årea

### Scraping
- ‚úÖ Melhorar extra√ß√£o de resultado
- ‚úÖ Cache de requisi√ß√µes
- ‚úÖ Rate limiting
- ‚úÖ Retry com backoff exponencial

### Banco de Dados
- ‚úÖ √çndices em campos frequentes
- ‚úÖ Eager loading para evitar N+1
- ‚úÖ Connection pooling otimizado

### APIs
- ‚úÖ Valida√ß√£o de dados
- ‚úÖ Timeout configur√°vel
- ‚úÖ Retry autom√°tico

### Monitoramento
- ‚úÖ Health checks
- ‚úÖ Alertas cr√≠ticos
- ‚úÖ M√©tricas de performance

---

**Total de Melhorias Identificadas: 12**

**Prioridade Alta: 3** | **Prioridade M√©dia: 4** | **Prioridade Baixa: 5**

